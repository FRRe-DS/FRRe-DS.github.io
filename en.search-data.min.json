[{"id":0,"href":"/trabajos-practicos/tp_01/","title":"Trabajo Práctico Número 1","parent":"Trabajos Prácticos","content":" Objetivos Que el alumno logre:\nAdquirir habilidades y conocimiento de las principales características y capacidades de las diferentes tecnologías y herramientas para el desarrollo y construcción de aplicaciones informáticas actuales. Aplicar criterios de selección de software en base a características y necesidades de un sistema. Adquirir habilidades en búsqueda y organización de información. Modalidad de Desarrollo Grupal: en grupos de entre 4 y 7 alumnos.\nFormato de Presentación Individual con coloquio en máquina e informe impreso y digital (formato .odt .doc .pdf).\nFecha de Entrega 21/04/2022 Exposición Grupal 22/04/2022 Contenido del Informe de Presentación Formato de hoja: A4. Carátula: Nombre de la materia, año de cursado, número de grupo, nombre completo de los integrantes. Correo electrónico de cada integrante. Índice de contenidos: índice temático de contenidos, organizado por lenguaje o herramientas de programación. Informe comparativo: Descripción de cada sistemas de control de versiones / plataforma evaluando cada una de las características seleccionadas. Extensión de No más de tres páginas por herramienta. Cuadro Comparativo: Cuadro sinóptico resumen de doble entrada (característica x herramienta) conteniendo los principales ítems y cuantificaciones. Bibliografía: Citación de Fuentes de referencia de la documentación o bibliografía consultada. Aspectos de Evaluación Cumplimiento de actividades propuestas y fechas indicadas. Investigación y desarrollo del material. Presentación. La correcta redacción de los textos, su ortografía y puntuación. La relación y coherencia en cuanto a los tipos de letras utilizados para los capítulos, partes o secciones componentes del informe. Actividad 1: Informe de investigación de Sistema de Control de Versiones Investigar y elaborar un breve informe de sistemas de control de versiones disponibles en el mercado, tanto del tipo centralizado como descentralizado (entre 5 y 8, ejemplo git, mercurial, svn, cvs, bitkeeper, etc). Indicar los siguientes ítems: Tipos de versionado soportados. Licencia Costo (gratuito / propietario) Quien lo mantiene. Plataformas soportadas (Windows, Unix, etc) Extras Elaborar un cuadro comparativo que resuma los puntos antes mencionados Realizar el mismo cuadro con plataformas comerciales de sistemas de control de versiones (entre 5 y 8, por ejemplo Atlassian, Github, etc) agregando la columna sistemas de control de versiones que soporta mencionadas en el punto anterior. Además mencionar que herramientas adicionales incluyen (por ejemplo wiki, herramientas de gestión de proyectos, etc). Actividad 2: Análisis y utilización de un Sistema de Control de Versiones Centralizado Investigar un SCV Centralizado o Descentralizado (distinto de git) y explicar las principales características brevemente. Enumerar ventajas y desventajas, y comparación con SCV Descentralizados (cuadro comparativo). Seleccionar un servidor que se encuentre en la nube/web gratuito para realizar un ejemplo. Realizar un ejemplo iniciar el repositorio, clonarlo, modificarlo y generar conflictos, crear ramas y realizar merge de las mismas con el trunk principal, en un pequeño equipo por lo menos 3 miembros del grupo. Utilizar de ser necesario una herramienta cliente (gráfico o consola) o IDE. Documentar el ejemplo con capturas de commits de los miembros del equipo sobre un mismo archivo y otro ejemplo de branch y merge. Actividad 3: Actividad práctica sobre Git y Github Utilizando Git por línea de comandos o desde la Web de Github (según corresponda) realizar el siguiente ejercicio (ir evidenciando documentando los pasos ver nota al final):\nUn miembro del equipo va a clonar el siguiente repositorio y va a crear una rama para el grupo (la misma va a tener la forma GX/principal donde X es el número de grupo). En su repositorio local el usuario va a crear un va a crear una carpeta de grupo (grupoX) y dentro de la misma va crear un proyecto en Node.js. Commitear los cambios en el repositorio y subir la rama al servidor remoto. Les dejo un link de ayuda: Link 1 Link 2 Una vez creada la rama del grupo en el servidor uno de los miembros del grupo va hacer un fork de la rama. Clona el fork, va a insertar una función que imprime en un label una entrada de pantalla, commit.\u0026gt; push y pull request al repositorio del grupo. Los demás miembros del grupo: Clonar el repositorio y toman la rama del grupo. A partir de la rama del grupo, crean una rama personal (gXiniciales grupo X e 2 iniciales) donde realizar una modificación en código (insertar una función que transforme el formato de un texto, que calcule una suma y la muestre en pantalla, etc) y realizar un commit y push, (Generar un conflicto y resolverlo). Ponerse de acuerdo en el grupo. Realizar un pull request de la rama personal a la principal de grupo. Aceptar / confirmar los pull request en la web, obtener a la funcionalidad completa del programa. Generar un tag para la versión con el nombre gX-V-1.0.0 X número de grupo (por línea de comando) y subir al repositorio remoto. Realizar un cambio en el programa sobre la rama principal del grupo y subir el cambio (que introduce un error al programa). Revertir los cambios al commit del tag creado anteriormente y subir los cambios rama principal. A partir de la rama principal (del grupo) crear una rama de test (para cambios futuros) introducir un par de commits que tengan nuevas funcionalidades y llevar a la rama principal solo el commit que se agregó anterior al head de la rama test. "},{"id":1,"href":"/trabajos-practicos/tp_02/","title":"Trabajo Práctico Número 2","parent":"Trabajos Prácticos","content":" Objetivos Que el alumno logre:\nAdquirir habilidades y conocimiento de las principales características y capacidades de las diferentes tecnologías y herramientas para el desarrollo y construcción de aplicaciones informáticas actuales. Aplicar criterios de selección de software en base a características y necesidades de un sistema. Adquirir habilidades en búsqueda y organización de información. Modalidad de Desarrollo Grupal: en grupos de entre 4 y 7 alumnos.\nFormato de Presentación Individual con coloquio en máquina e informe impreso y digital (formato .odt .doc .pdf).\nFecha de Entrega 21/06/2022 Exposición Grupal 21/06/2022 Contenido del Informe de Presentación Formato de hoja: A4. Carátula: Nombre de la materia, año de cursado, número de grupo, nombre completo de los integrantes. Correo electrónico de cada integrante. Índice de contenidos: índice temático de contenidos. Cuadro Comparativo: Cuadro sinóptico resumen de doble entrada (característica x herramienta) conteniendo los principales ítems y cuantificaciones. Bibliografía: Citación de Fuentes de referencia de la documentación o bibliografía consultada. Aspectos de Evaluación Cumplimiento de actividades propuestas y fechas indicadas. Investigación y desarrollo del material. Presentación. La correcta redacción de los textos, su ortografía y puntuación. La relación y coherencia en cuanto a los tipos de letras utilizados para los capítulos, partes o secciones componentes del informe. Actividad 1: Informe conceptos de Docker y ejemplo práctico Conceptos teóricos:\nIntroducción a Docker. Ventajas y desventajas de utilizar Docker. Diferencias de Docker respecto de Máquinas virtuales. Cuadro comparativo. Breve descripción de los siguientes conceptos: imágen, Dockerfile, container, volúmenes y links. Docker-compose. Diferencias con Dockerfile. Diferencias con Kubernetes. Introducción a multistage builds con Docker. Ejemplo práctico:\nDesarrollar un API Rest en Node.js (debe tener al menos un CRUD de un recurso) que utilice una base de datos (relacional o no relacional) y desplegarlo en Docker. El API Rest debe contemplar variables de entorno para configurar el mismo desde el docker-compose. Para ello realizar las siguientes tareas: Utilizar una imagen de Docker de la base de datos elegida. Construir la imagen de Docker de la API Rest utilizando multi-stage builds. Construir un docker-compose para instalar y desinstalar la aplicación. En el archivo README.md del repositorio del trabajo práctico deben quedar reflejado los siguientes comandos: Instalación / construcción de la aplicación. Deploy / undeploy en Docker de la aplicación. Nota: Crear una rama identificando al grupo para subir el código al repositorio. Tener en cuenta el tamaño de las imágenes utilizadas.\nRepositorio: https://github.com/FRRe-DACS/TP2-Docker-2022\n"},{"id":2,"href":"/teoria-practicos/acceso-datos/orm/","title":"Object Relational Mapping","parent":"Capa de Acceso a Datos","content":" ¿Qué es una ORM? Una ORM procede de las siglas (Object Relational Mapping). Es un modelo de programación que transforma las tablas de las bases de datos en entidades para simplificar enormemente la tarea del programador. El trabajo deja de ser manual ya que el ORM lo realizara de forma independiente de la base de datos. Además, gracias al mapeo automático podrás cambiar el motor de la base de datos fácilmente.\n¿Por qué es mejor un ORM que otro lenguaje de programación? Un ORM tiene algunas ventajas y desventajas también. Sus ventajas son la facilidad y velocidad de uso, la seguridad contra ataques informáticos o la forma de abstracción de la base de datos que estemos utilizando. Por otro lado, para programar con ORM es necesario aprender su lenguaje y hay entornos con gran volumen que puede ver mermado su rendimiento. Uno de los mapeos automáticos más utilizado es de Java y se llama Hibernate, pero también están iBatis, Ebean, para .Net nHibernate , Entity Framework, entre otros.\nORM Sequelize Es un ORM de Node.js basado en promesas para Postgres, MySql, MariaDB, SQLite, Microsoft SQL Server. Cuenta con un sólido soporte de transacciones, relaciones, carga ansiosa, y perezosa, replicación de lectura y mucho más.\nComando para instalar el módulo de Sequelize\n$ npm install --save sequelize Modelo Un modelo es una abstracción que representa una tabla en una base de datos. En Sequelize, es una clase que extiende de Model. El modelo le dice a Sequelize varias cosas sobre la entidad que representa, como el nombre de la tabla de la bases de datos y que columna tiene y sus tipos. Un modelo en Sequelize tiene un nombre. Este nombre no tiene que ser el mismo nombre de la tabla que representa en la base de datos. Por lo general, los modelos tienen nombres en singular (como User) mientras que las tablas tienen nombres en plural (como Users).\nDefinición de Modelos Los modelos se pueden definir de dos maneras equivalentes en Sequelize:\n•\tSequelize define(modelName, attributes, options)\n•\tExtendiendo el modelo y llamando init(attributes, options) Utilizando sequealize.\nconst { Sequelize, DataTypes } = require(\u0026#39;sequelize\u0026#39;); const sequelize = new Sequelize(\u0026#39;sqlite::memory:\u0026#39;); const User = sequelize.define(\u0026#39;User\u0026#39;, { // Model attributes are defined here firstName: { type: DataTypes.STRING, allowNull: false }, lastName: { type: DataTypes.STRING // allowNull defaults to true } }, { // Other model options go here }); // `sequelize.define` also returns the model console.log(User === sequelize.models.User); // true Modelo Extensible const { Sequelize, DataTypes, Model } = require(\u0026#39;sequelize\u0026#39;); const sequelize = new Sequelize(\u0026#39;sqlite::memory\u0026#39;); class User extends Model {} User.init({ // Model attributes are defined here firstName: { type: DataTypes.STRING, allowNull: false }, lastName: { type: DataTypes.STRING // allowNull defaults to true } }, { // Other model options go here sequelize, // We need to pass the connection instance modelName: \u0026#39;User\u0026#39; // We need to choose the model name }); // the defined model is the class itself console.log(User === sequelize.models.User); // true Sincronización de Modelos Cuando define un modelo, le está diciendo a Sequelize algunas cosas sobre su tabla en la base de datos. Sin embargo, ¿qué pasa si la tabla ni siquiera existe en la base de datos? ¿Qué pasa si existe, pero tiene diferentes columnas, menos columnas o cualquier otra diferencia? Aquí es donde entra en juego la sincronización del modelo. Un modelo se puede sincronizar con la base de datos llamando a model.sync(options)una función asincrónica (que devuelve una Promise). Con esta llamada, Sequelize realizará automáticamente una consulta SQL a la base de datos. Tenga en cuenta que esto cambia solo la tabla en la base de datos, no el modelo en el lado de JavaScript.\n•\tUser.sync() - Esto crea la tabla si no existe (y no hace nada si ya existe)\n•\tUser.sync({ force: true }) - Esto crea la tabla, soltándola primero si ya existía\n•\tUser.sync({ alter: true }) - Esto verifica cuál es el estado actual de la tabla en la base de datos (qué columnas tiene, cuáles son sus tipos de datos, etc.), y luego realiza los cambios necesarios en la tabla para que coincida con el modelo.\nEjemplo\nawait User.sync({ force: true }); console.log(\u0026#34;The table for the User model was just (re)created!\u0026#34;); Sincronizar todos los modelos a la vez Puede utilizar sequelize.sync() para sincronizar automáticamente todos los modelos.\nEjemplo\nawait sequelize.sync({ force: true }); console.log(\u0026#34;All models were synchronized successfully.\u0026#34;); Instancia del Modelo Una instancia de la clase representa un objeto de ese modelo (que se asigna a una fila de la tabla en la base de datos). De esta forma, las instancias de modelo son DAO.\nconst { Sequelize, Model, DataTypes } = require(\u0026#34;sequelize\u0026#34;); const sequelize = new Sequelize(\u0026#34;sqlite::memory:\u0026#34;); const User = sequelize.define(\u0026#34;user\u0026#34;, { name: DataTypes.TEXT, favoriteColor: { type: DataTypes.TEXT, defaultValue: \u0026#39;green\u0026#39; }, age: DataTypes.INTEGER, cash: DataTypes.INTEGER }); (async () =\u0026gt; { await sequelize.sync({ force: true }); // Code here })(); Consulta de Modelo Consulta INSERT Primero, un ejemplo simple:\n// Create a new user const jane = await User.create({ firstName: \u0026#34;Jane\u0026#34;, lastName: \u0026#34;Doe\u0026#34; }); console.log(\u0026#34;Jane\u0026#39;s auto-generated ID:\u0026#34;, jane.id); El Model.create() método es una forma abreviada de crear una instancia sin Model.build() guardar y guardar la instancia con instance.save().\nTambién es posible definir qué atributos se pueden configurar en el createmétodo. Esto puede ser especialmente útil si crea entradas de base de datos basadas en un formulario que puede ser llenado por un usuario. Usar eso, por ejemplo, le permitiría restringir el Usermodelo para establecer solo un nombre de usuario y una dirección, pero no una marca de administrador:\nconst user = await User.create({ username: \u0026#39;alice123\u0026#39;, isAdmin: true }, { fields: [\u0026#39;username\u0026#39;] }); // let\u0026#39;s assume the default of isAdmin is false console.log(user.username); // \u0026#39;alice123\u0026#39; console.log(user.isAdmin); // false Consulta SELECT Puede leer la tabla completa de la base de datos con el findAll método.\n// Find all users const users = await User.findAll(); console.log(users.every(user =\u0026gt; user instanceof User)); // true console.log(\u0026#34;All users:\u0026#34;, JSON.stringify(users, null, 2)); SELECT * FROM \u0026hellip; Especificar atributos para consultas SELECT Para seleccionar solo algunos atributos, puede usar la attributesopción:\nModel.findAll({ attributes: [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;] }); SELECT foo, bar FROM \u0026hellip; Se puede cambiar el nombre de los atributos mediante una matriz anidada:\nModel.findAll({ attributes: [\u0026#39;foo\u0026#39;, [\u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;], \u0026#39;qux\u0026#39;] }); SELECT foo, bar AS baz, qux FROM \u0026hellip; Puede usar sequelize.fnpara hacer agregaciones:\nModel.findAll({ attributes: [ \u0026#39;foo\u0026#39;, [sequelize.fn(\u0026#39;COUNT\u0026#39;, sequelize.col(\u0026#39;hats\u0026#39;)), \u0026#39;n_hats\u0026#39;], \u0026#39;bar\u0026#39; ] }); SELECT foo, COUNT(hats) AS n_hats, bar FROM \u0026hellip; Cuando utilice la función de agregación, debe darle un alias para poder acceder a ella desde el modelo. En el ejemplo anterior, puede obtener el número de sombreros con instance.n_hats. A veces puede resultar tedioso enumerar todos los atributos del modelo si solo desea agregar una agregación:\n// This is a tiresome way of getting the number of hats (along with every column) Model.findAll({ attributes: [ \u0026#39;id\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;, \u0026#39;qux\u0026#39;, \u0026#39;hats\u0026#39;, // We had to list all attributes... [sequelize.fn(\u0026#39;COUNT\u0026#39;, sequelize.col(\u0026#39;hats\u0026#39;)), \u0026#39;n_hats\u0026#39;] // To add the aggregation... ] }); // This is shorter, and less error prone because it still works if you add / remove attributes from your model later Model.findAll({ attributes: { include: [ [sequelize.fn(\u0026#39;COUNT\u0026#39;, sequelize.col(\u0026#39;hats\u0026#39;)), \u0026#39;n_hats\u0026#39;] ] } }); SELECT id, foo, bar, baz, qux, hats, COUNT(hats) AS n_hats FROM \u0026hellip; Consulta de Actualización Las consultas de actualización también aceptan la where opción, al igual que las consultas de lectura que se muestran arriba.\n// Change everyone without a last name to \u0026#34;Doe\u0026#34; await User.update({ lastName: \u0026#34;Doe\u0026#34; }, { where: { lastName: null } }); Consulta de Eliminación Las consultas de eliminación también aceptan la where opción, al igual que las consultas de lectura que se muestran arriba.\n// Delete everyone named \u0026#34;Jane\u0026#34; await User.destroy({ where: { firstName: \u0026#34;Jane\u0026#34; } }); Para destruir todo lo que TRUNCATEse puede usar el SQL:\n// Truncate the table await User.destroy({ truncate: true }); Validaciones y Restricciones const { Sequelize, Op, Model, DataTypes } = require(\u0026#34;sequelize\u0026#34;); const sequelize = new Sequelize(\u0026#34;sqlite::memory:\u0026#34;); const User = sequelize.define(\u0026#34;user\u0026#34;, { username: { type: DataTypes.TEXT, allowNull: false, unique: true }, hashedPassword: { type: DataTypes.STRING(64), is: /^[0-9a-f]{64}$/i } }); (async () =\u0026gt; { await sequelize.sync({ force: true }); // Code here })(); Diferencia entre validaciones y restricciones Las validaciones son comprobaciones realizadas en el nivel Sequelize, en JavaScript puro. Pueden ser arbitrariamente complejos si proporciona una función de validación personalizada, o pueden ser uno de los validadores integrados que ofrece Sequelize. Si falla una validación, no se enviará ninguna consulta SQL a la base de datos. Por otro lado, las restricciones son reglas definidas a nivel de SQL. El ejemplo más básico de restricción es una restricción única. Si falla una verificación de restricción, la base de datos arrojará un error y Sequelize enviará este error a JavaScript (en este ejemplo, arrojará un SequelizeUniqueConstraintError). Tenga en cuenta que en este caso se realizó la consulta SQL, a diferencia del caso de las validaciones.\nPermitir y Rechazar valores nulos De forma predeterminada, nulles un valor permitido para cada columna de un modelo. Esto se puede deshabilitar configurando la allowNull: false opción para una columna.\n/* ... */ { username: { type: DataTypes.TEXT, allowNull: false, unique: true }, } /* ... */ Biblioteca de Conectores MySQL La biblioteca de conectores subyacente utilizada por Sequelize para MySQL es el paquete mysql2 npm (versión 1.5.2 o superior).\nPuede proporcionarle opciones personalizadas usando dialectOptionsen el constructor Sequelize:\nconst sequelize = new Sequelize(\u0026#39;database\u0026#39;, \u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;, { dialect: \u0026#39;mysql\u0026#39;, dialectOptions: { // Your mysql2 options here } }) MariaDB La biblioteca de conectores subyacente utilizada por Sequelize para MariaDB es el paquete mariadb npm.\nPuede proporcionarle opciones personalizadas usando dialectOptionsen el constructor Sequelize:\nconst sequelize = new Sequelize(\u0026#39;database\u0026#39;, \u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;, { dialect: \u0026#39;mariadb\u0026#39;, dialectOptions: { // Your mariadb options here // connectTimeout: 1000 } }); SQLite La biblioteca de conectores subyacente utilizada por Sequelize para SQLite es el paquete sqlite3 npm (versión 4.0.0 o superior).\nEl archivo de almacenamiento se especifica en el constructor Sequelize con la storageopción (utilizar :memory:para una instancia de SQLite en memoria). Puede proporcionarle opciones personalizadas usando dialectOptionsen el constructor Sequelize:\nconst sequelize = new Sequelize(\u0026#39;database\u0026#39;, \u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;, { dialect: \u0026#39;sqlite\u0026#39;, storage: \u0026#39;path/to/database.sqlite\u0026#39; // or \u0026#39;:memory:\u0026#39; dialectOptions: { // Your sqlite3 options here } }); PostgreSQL La biblioteca de conectores subyacente utilizada por Sequelize para PostgreSQL es el paquete pg npm (versión 7.0.0 o superior). El módulo pg-hstore también es necesario.\nPuede proporcionarle opciones personalizadas usando dialectOptionsen el constructor Sequelize:\nconst sequelize = new Sequelize(\u0026#39;database\u0026#39;, \u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;, { dialect: \u0026#39;postgres\u0026#39;, dialectOptions: { // Your pg options here } }); Para conectarse a través de un socket de dominio Unix, especifique la ruta al directorio del socket en la hostopción. La ruta del socket debe comenzar con /.\nconst sequelize = new Sequelize(\u0026#39;database\u0026#39;, \u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;, { dialect: \u0026#39;postgres\u0026#39;, host: \u0026#39;/path/to/socket_directory\u0026#39; }); MSSQL La biblioteca de conectores subyacente utilizada por Sequelize para MSSQL es el tedioso paquete npm (versión 6.0.0 o superior).\nPuede proporcionarle opciones personalizadas usando dialectOptions.optionsen el constructor Sequelize:\nconst sequelize = new Sequelize(\u0026#39;database\u0026#39;, \u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;, { dialect: \u0026#39;postgres\u0026#39;, dialectOptions: { // Observe the need for this nested `options` field for MSSQL options: { // Your tedious options here useUTC: false, dateFirst: 1 } } }); Migraciones Al igual que usa sistemas de control de versiones como Git para administrar los cambios en su código fuente, puede usar las migraciones para realizar un seguimiento de los cambios en la base de datos. Con las migraciones, puede transferir su base de datos existente a otro estado y viceversa: esas transiciones de estado se guardan en archivos de migración, que describen cómo llegar al nuevo estado y cómo revertir los cambios para volver al estado anterior.\nNecesitará Sequelize Command-Line Interface (CLI). La CLI incluye soporte para migraciones y arranque de proyectos.\nUna migración en Sequelize es un archivo javascript que exporta dos funciones, up y down que dictan cómo realizar la migración y deshacerla. Define esas funciones manualmente, pero no las llama manualmente; la CLI los llamará automáticamente. En estas funciones, simplemente debe realizar las consultas que necesite, con la ayuda de sequelize.querycualquier otro método que Sequelize le proporcione. No hay magia adicional más allá de eso.\nInstalación del CLI Para instalar la CLI de Sequelize:\nnpm install --save-dev sequelize-cli "},{"id":3,"href":"/teoria-practicos/versionado/","title":"Sistemas de Control de Versiones","parent":"Teoría Trabajos Prácticos","content":" ¿Qué es un Sistema de control de versiones? Un Sistema de Versionado de Código (SVC) en abstracto es lo que nos permite compartir el código fuente de nuestros desarrollos y a la vez mantener un registro de los cambios por los que va pasando.\nHabitualmente para gestionar las distintas versiones por las que pasa el código fuente de las aplicaciones, lo que nos permite saber quién realiza qué cambios y poder volver a ellos en un determinado momento. Los más utilizados en este campo a lo largo del tiempo (aunque existen bastante más) son CVS, Subversion y Git\nVer presentación: Sistemas de control de versiones\n¿Porqué usar un control de versiones nos hará felices? ● Proporciona copias de seguridad automáticas de los ficheros.\n● Permite volver a un estado anterior de nuestros ficheros.\n● Ayuda a trabajar de una forma más organizada.\n● Permite trabajar de forma local, sin conexión con servidor. (en distribuídos).\n● Permite que varias personas trabajen en los mismos ficheros.\n● Permiten trabajar en varias funcionalidades en paralelo separado (ramas).\nEl antes y el después de conocer los sistemas de control de versiones En algún momento de nuestras vidas nuestra carpeta de documentos luciera como la de la imagen y nos haya tocado recurrir a tener muchas copias de nuestros proyectos.\nTiempo después por algún accidente del destino conocemos los sistemas de control de versiones y no podemos negarlo, nuestras vidas cambian y entramos a una era donde todo es mucho más bonito: el después. El control de versiones es un sistema que registra los cambios realizados sobre un archivo o conjunto de archivos a lo largo del tiempo de tal manera que sea posible recuperar versiones especificas más adelante\nTipos de Sistemas de Control de Versiones Sistemas de Control de Versiones Locales En vez de mantener las versiones como archivos independientes, los almacenaban en una base de datos.\nEN cualquier momento solo se tenia una copia del proyecto, eliminando la posibilidad de confundir o eliminar versiones. En este punto el control de versiones se llevaba a cabo en el computador de cada uno de los desarrolladores y no existía una manera eficiente de compartir el código entre ellos\nSistemas de Control de Versiones Centralizados Para facilitar la colaboración de múltiples desarrolladores en un solo proyecto los sistemas de control de versiones evolucionaron: en vez de almacenar los cambios y versiones en el disco duro de los desarrolladores, estos se almacenaban en un servidor. los sistemas centralizados trajeron consigo nuevos retos: ¿Cómo trabajaban múltiples usuarios en un mismo archivo al mismo tiempo? Los sistemas de control de versiones centralizados abordaron este problema impidiendo que los usuarios invalidaran el trabajo de los demás. Si dos personas editaban el mismo archivo y se presentaba un conflicto alguien debía solucionar este problema de manera manual y el desarrollo no podía continuar hasta que todos los conflictos fueran resueltos y puestos a disposición del resto del equipo.\nEsta solución funcionó en proyectos que tenían relativamente pocas actualizaciones y por ende pocos conflictos pero resulto muy engorroso para proyectos con docenas de contribuyentes activos que realizaban actualizaciones a diario.\nSistemas de Control de Versiones Distribuidos Este SCV optó por darle a cada desarrollador una copia local de todo el proyecto, de esta manera se construyo una red distribuida de repositorios, en la que cada desarrollador podía trabajar de manera aislada pero teniendo un mecanismo de resolución de conflictos mucho más elegante que un su versión anterior. Al no existir un repositorio central, cada desarrollador puede trabajar a su propio ritmo, almacenar los cambios a nivel local y mezclar los conflictos que se presenten solo cuando se requiera. Cómo cada usuario tiene una copia completa del proyecto el riesgo por una caída del servidor, un repositorio dañado o cualquier otro tipo de perdida de datos es mucho menor que en cualquiera de sus predecesores\nEjemplos de SCV CVS CVS (Concurrent Versions System) es uno de los primeros sistemas de control de versiones. Tiene una arquitectura cliente-­servidor, en la que el código está almacenado en un servidor central y con el software cliente podemos hacer una copia del código local para hacer cambios y posteriormente volver a subirla al servidor. Permite el trabajo concurrente entre distintos programadores, pero el servidor solo acepta actualizaciones de los ficheros que estén en la última versión, de forma que los propios usuarios deben actualizar sus copias locales antes de subirlas al servidor. Soporta además el trabajo en distintas ramas. Se hizo bastante popular entre la comunidad de software libre por ser lanzado bajo la licencia GNU.\nSVN El proyecto de Subversion surgió en el año 2000 con el objetivo crear un sistema de\u000bcontrol de versiones con la misma filosofía que CVS, pero arreglando problemas y cubriendo carencias del mismo:\n● Commits atómicos, en CVS un commit interrumpido puede dejar datos inconsistentes.\n● La creación de ramas es más eficiente, con complejidad constante a diferencia de CVS que es lineal (aumenta con el número de ramas).\n● Manejo de archivos binarios como tal, CVS los trata como archivos de texto.\n● Envía los incrementos de los ficheros en la comunicación cliente­servidor, en lugar de los ficheros completos como CVS.\nLa estructura más habitual en un repositorio SVN:\n● Trunk con la versión del código principal.\n● Tags para almacenar las distintas versiones de una aplicación que no volverán a modificarse.\n● Branches para gestionar las distintas versiones de código que se desarrollan paralelas al trunk Al ser también software libre, ha sido adoptado por multitud de proyectos, incluso en grandes corporaciones, convirtiéndose en un referente.\nGIT En 2005, Linus Torvalds inició el desarrollo de Git como alternativa a BitKeeper (que había pasado a ser SW propietario), el sistema de control de versiones que se usó hasta el momento para desarrollar el kernel de Linux. Por esto, Git nace con las principales necesidades de ser rápido, eficiente y distribuido:\n● Rápido: combinando el trabajo sobre el repositorio local y la posterior distribución remota.\n● Eficiente: pensado para manejar grandes proyectos con muchos ficheros (Linux) y no se vuelve lento a medida que la historia del proyecto crece.\n● Distribuido: fundamental para el trabajo concurrente y en remoto de muchos usuarios. Cada usuario tiene una copia local en la que trabajar, que posteriormente sincroniza con el resto de usuarios. Es también especialmente efectivo a la hora de mezclar los cambios hechos por distintos usuarios.\nCaracterísticas Su sencillez es lo que lo diferencia de otros sistemas de control de versiones y lo que le hace verdaderamente potente.\nLa mayoría de sistemas del momento almacenaban los cambios (deltas) en los ficheros entre distintas versiones y requerían de complejos algoritmos de aplicación de esos deltas para recuperar un determinado estado del repositorio. Git en cambio es una sencilla base de datos clave­-valor, en la que cada versión apunta a un árbol de nodos que representa la estructura de directorios y contenidos comprimidos de los ficheros. Esto le permite recuperar estados únicamente apuntando a un determinado árbol y facilita las tareas de distribución y mezclado de contenidos\nDistribuido: cada usuario dispone de un repositorio completo de forma local. Esto permite trabajar sin necesidad de conexión a un servidor para realizar las distintas acciones, pudiendo más tarde sincronizar nuestros datos con el servidor.\nOtra de las particularidades de Git es el área de stage. La gran mayoría de sistemas almacenan la información en dos sitios, la copia lo al de ficheros y directorios del usuario, y el almacenamiento de versiones.\nGit proporciona una tercera opción con el área de stage. Consiste en un área intermedia entre las otras dos, donde ir colocando los cambios de la copia local con las que queremos hacer un nuevo commit. De esta forma se consigue mucha más versatilidad y control a la hora de ir guardando versiones del código.\u000b"},{"id":4,"href":"/trabajos-practicos/tp-final/","title":"Trabajo Práctico Final","parent":"Trabajos Prácticos","content":" Objetivos Que el alumno logre:\nAdquirir habilidades prácticas sobre los conocimientos impartidos en las principales tecnologías y herramientas para el desarrollo y construcción de aplicaciones informáticas actuales. Modalidad de Desarrollo Grupal: en grupos de entre 4 y 7 alumnos.\nFormato de Presentación Individual con coloquio en máquina e informe impreso y digital (formato .odt .doc .pdf).\nFecha de Entrega 01/07/2022 Contenido del Informe de Presentación Formato de hoja: A4. Carátula: Nombre de la materia, año de cursado, número de grupo, nombre completo de los integrantes. Correo electrónico de cada integrante. índice de contenidos: índice temático de contenidos, organizado por lenguaje o herramientas de programación. Informe detallado: Descripción de las decisiones de diseño y de las soluciones implementadas para cumplimentar el práctico. Aspectos de Evaluación La evolución de trabajo se realizará de acuerdo a la siguiente tabla:\nAspecto Item Condición Puntaje Cumplimiento funcional de la aplicación Funcionalidad Mandatorio 15 Arquitectura empleada Multiplataforma Opcional 10 Cliente Liviano y cliente móvil Mandatorio 10 Acceso a Datos Base de Datos Mandatorio 10 ORM Opcional 10 Lógica de Negocios Mandatorio Validación de Datos Opcional 5 Exposición de Servicios (Web Services) Mandatorio 15 Presentación Usabilidad Mandatorio 10 MVC Opcional 10 Estilos Opcional 5 Total 100 Actividad 1: Escenario En vísperas al mundial de Qatar 2022 la empresa Fantastic Tour (FANTUR S.A.) ha solicitado a los alumnos de la materia Desarrollo de Aplicaciones Cliente-Servidor el desarrollo de un sistema para la venta y administración de paquetes turísticos.\nEl sistema debe permitir a los clientes registrar en forma electrónica, realizar consultas de paquetes, reservar paquetes y abobar los mismo por diferentes medios (tarjetas de crédito o otros sistemas de pago on-line) y enviar publicidad (via e-mail) a sus clientes.\nLa mayoría de los paquetes turísticos que la empresa comercializa están compuesto por pasajes aéreos o en micro, estadía en hoteles, seguros médicos COVID-19 y entradas a espectáculos. La aplicación debe contemplar el armado y cotización de estos paquetes turísticos por parte de los administradores de la empresa, pudiendo establecerse cuales paquetes están disponibles o hasta que fecha pueden adquirirse.\nDebido a las imposiciones impuestas por los organismos de control que rigen la actividad del sector, las agencias de turismos (incluida FANTUR) deben solicitar permisos al organismo de contralor antes de confirmar a las operaciones a sus clientes. Este tipo de solicitudes deber ser realizar en forma on-line y por medio de un web-service que el organismo provee.\nInformacion del servicio\nEste servicio no fue desarrollado por los alumnos de la cátedra Desarrollo de Aplicaciones Cliente-Servidor, por lo cual la tasa de error del mismo es aleatoria y deberá ser tenida en cuenta a la hora de utilizarlo.\nContar con una aplicación para teléfonos móviles donde los usuarios puedan consultar u operar sería una muy buena ventaja competitiva para esta empresa.\nDesarrollo Para el desarrollo del TP, los grupos deberán definir, coordinando entre ellos, las APIs de los diferentes actores y publicarlas en el sitio web de la materia (por medio de PRs).\nPor ejemplo: para la definición de las APIs, los diferentes grupos deberán generar, en forma colaborativa el documento de Definición de APIs. Esto lo deberán hacer, haciendo un fork de repositorio del sitio web, generando la documentación y realizando un PR, como se dio en el TP 1.\n"},{"id":5,"href":"/trabajos-practicos/tp-final/2021/","title":"Trabajo Práctico Final - Año 2021","parent":"Trabajo Práctico Final","content":" Objetivos Que el alumno logre:\nAdquirir habilidades prácticas sobre los conocimientos impartidos en las principales tecnologías y herramientas para el desarrollo y construcción de aplicaciones informáticas actuales. Modalidad de Desarrollo Grupal: en grupos de entre 4 y 7 alumnos.\nFormato de Presentación Individual con coloquio en máquina e informe impreso y digital (formato .odt .doc .pdf).\nFecha de Entrega 02/07/2021 Contenido del Informe de Presentación Formato de hoja: A4. Carátula: Nombre de la materia, año de cursado, número de grupo, nombre completo de los integrantes. Correo electrónico de cada integrante. índice de contenidos: índice temático de contenidos, organizado por lenguaje o herramientas de programación. Informe detallado: Descripción de las decisiones de diseño y de las soluciones implementadas para cumplimentar el práctico. Aspectos de Evaluación La evolución de trabajo se realizará de acuerdo a la siguiente tabla:\nAspecto Item Condición Puntaje Cumplimiento funcional de la aplicación Funcionalidad Mandatorio 15 Arquitectura empleada Multiplataforma Opcional 10 Cliente Liviano y cliente móvil Mandatorio 10 Acceso a Datos Base de Datos Mandatorio 10 ORM Opcional 10 Lógica de Negocios Mandatorio Validación de Datos Opcional 5 Exposición de Servicios (Web Services) Mandatorio 15 Presentación Usabilidad Mandatorio 10 MVC Opcional 10 Estilos Opcional 5 Total 100 Actividad 1: Escenario Desarrollo Para el desarrollo del TP, los grupos deberán definir, coordinando entre ellos, las APIs de los diferentes actores y publicarlas en el sitio web de la materia (por medio de PRs).\nPor ejemplo: para la definición de las APIs, los diferentes grupos deberán generar, en forma colaborativa el documento de Definición de APIs. Esto lo deberán hacer, haciendo un fork de repositorio del sitio web, generando la documentación y realizando un PR, como se dio en el TP 1.\n"},{"id":6,"href":"/programa-analitico/unidad-01/","title":"UNIDAD 1","parent":"Programa Analítico","content":" Introducción a las aplicaciones cliente-servidor Repaso de las arquitecturas más comunes en sistemas distribuidos. Modelo de capas. Dos y tres capas. Modelo de tres capas, la tendencia actual. Modelo distribuido y de microservices, introducción. Interfaces de acceso a los datos: ODBC, OLE DB y los objetos ADO. JDBC. Publicadores y consumidores de datos. Patrones de diseño en arquitecturas distribuidas, Event-Sourcing.\nObjetivos específicos Discriminar las diferencias conceptuales entre las distintas tecnologías existentes. "},{"id":7,"href":"/teoria-practicos/acceso-datos/","title":"Capa de Acceso a Datos","parent":"Teoría Trabajos Prácticos","content":" Node.js NodeJs es un entorno de tiempo de ejecución de JavaScript (de ahí su terminación en .js).\nNodeJs fue creado por los desarrolladores originales de JavaScript. Lo transformaron en algo que solo se podía ejecutarse en el navegador en algo que se podría ejecutar en los ordenadores como si de aplicaciones independiente se tratara . Tanto JavaScript como NodeJs se ejecutan en el motor de tiempo de ejecución JavaScript V8 (V8 es el nombre del motor de JavaScript que alimenta Google Chrome).\n¿Para que sirve Node.Js? Node.js utiliza un modelo de entrada y salida sin bloqueo controlado por eventos que lo hace ligero y eficiente (con entrada nos referimos a solicitudes y con salidas a respuestas). Puede referirse cualquier operación desde leer o escribir archivos de cualquier tipo hasta hacer una solicitud HTTP. La idea principal de Node.Js es usar un modelo de entrada y salida sin bloqueo y controlado por eventos para seguir siendo liviano y eficiente frente a las aplicaciones en tiempo real de uso de datos que se ejecutan en los dispositivos. La finalidad de Node.Js no tiene su objetivo en operaciones intensivas en el uso del procesador, de hecho de usarlo para programación de más peso eliminara casi todas sus ventajas. Donde Node.Js realmente brilla es en la creación de aplicaciones de red rápidas, ya que es capaz de manejar gran cantidad de conexiones simultáneas con un alto nivel de rendimiento, lo que equivale a una alta escalabilidad.\nVentaja •\tTiene incorporado JavaScript en la plataforma de Node.Js, siendo un lenguaje fácil de aprender.\n•\tSe desarrolla en un entorno de tiempo de ejecución de fuentes libres que ayudara en el almacenamiento de creación de proyectos únicos.\n•\tEl modelo de entrada y salida impulsado por eventos ayuda mucho en el manejo simultaneo de peticiones.\nFrameworks de Acceso a Datos Respecto de Acceso a Datos hablaremos de los siguientes frameworks:\n• ORM - Object Relational Mapping\n• ODM - Object Document Mapper\n"},{"id":8,"href":"/teoria-practicos/acceso-datos/odm/","title":"Object Document Mapper","parent":"Capa de Acceso a Datos","content":" Introducción Cuando queremos guardar en una DB info solemos usar su lenguaje propio dentro de nuestro código. Pero a veces tenemos que hacer todo un esfuerzo para que este lenguaje de consulta funcione dentro de nuestro código. Esto se puede evitar con un orm, o un ODM en el caso de una base de datos no relacional como MongoDB. El ODM hace de intermediario entre la app y la DB así tenemos métodos propios que hacen todo el trabajo.\nMongoose MongooseJS es un Object Document Mapper (ODM) que facilita el uso de MongoDB al traducir documentos en una base de datos MongoDB a objetos en el programa. Además de MongooseJS, hay varios otros ODM que se han desarrollado para MongoDB, incluidos Doctrine, MongoLink y Mandango. Las cuatro ventajas principales de usar Mongoose frente a MongoDB nativo son:\n● MongooseJS proporciona una capa de abstracción sobre MongoDB que elimina la necesidad de utilizar colecciones con nombre.\n● Los modelos en Mongoose realizan la mayor parte del trabajo de establecer valores predeterminados para las propiedades del documento y validar los datos.\n● Las funciones se pueden adjuntar a los modelos en MongooseJS. Esto permite la incorporación perfecta de nuevas funciones.\n● Las consultas utilizan el encadenamiento de funciones en lugar de los mnemónicos incrustados que dan como resultado un código que es más flexible y legible, y por lo tanto más fácil de mantener.\nEl resultado neto de estos es la simplificación del acceso a la base de datos desde las aplicaciones. La principal desventaja de Mongoose es que la abstracción tiene un costo de rendimiento en comparación con el de MongoDB nativo.\n¿Por qué Mongoose si ya existe el cliente de mongoDB? Mongoose usa esquemas para modelar los datos que una aplicación desea almacenar y manipular en MongoDb. Esto incluye funciones como conversión de tipos, validación, creación de consultas y más. El esquema describe los atributos de las propiedades (también conocidos como campos) que la aplicación manipulara. Estos atributos incluyen cosas como:\n● Tipo de datos, en total son 8: String, Number, Date, Buffer (archivos onda PDF), Boolean, Mixed (puede venir cualquier cosa), ObjectId (links a otros documentos en la DB), Array.\n● Si es obligatorio u opcional.\n● Su valor por defecto.\n● Crear índices para que la información sea obtenida más rápido.\nGetters/Setters en Mongoose Una función GET que te permite manipular la información entrante antes de ser devuelta como objeto:\nconst userSchema = new Schema({ email: { type: String, get: obfuscate } }); // Mongoose passes the raw value in MongoDB `email` to the getter function obfuscate(email) { const separatorIndex = email.indexOf(\u0026#39;@\u0026#39;); if (separatorIndex \u0026lt; 3) { // \u0026#39;ab@gmail.com\u0026#39; -\u0026gt; \u0026#39;**@gmail.com\u0026#39; return email.slice(0, separatorIndex).replace(/./g, \u0026#39;*\u0026#39;) + email.slice(separatorIndex); } // \u0026#39;test42@gmail.com\u0026#39; -\u0026gt; \u0026#39;te****@gmail.com\u0026#39; return email.slice(0, 2) + email.slice(2, separatorIndex).replace(/./g, \u0026#39;*\u0026#39;) + email.slice(separatorIndex); } const User = mongoose.model(\u0026#39;User\u0026#39;, userSchema); const user = new User({ email: \u0026#39;ab@gmail.com\u0026#39; }); user.email; // **@gmail.com Una función SET que permite manipular los datos antes de ser guardados en la base de datos\nconst userSchema = new Schema({ email: { type: String, set: v =\u0026gt; v.toLowerCase() } }); const User = mongoose.model(\u0026#39;User\u0026#39;, userSchema); const user = new User({ email: \u0026#39;TEST@gmail.com\u0026#39; }); user.email; // \u0026#39;test@gmail.com\u0026#39; // The raw value of `email` is lowercased user.get(\u0026#39;email\u0026#39;, null, { getters: false }); // \u0026#39;test@gmail.com\u0026#39; user.set({ email: \u0026#39;NEW@gmail.com\u0026#39; }); user.email; // \u0026#39;new@gmail.com\u0026#39; Con mongoose todo deriva de un esquema, por ello se genera un modelo a partir del esquema y define un documento en el que operará la aplicación. Más precisamente, un modelo es una clase que define un documento con las propiedades y comportamientos declarados en nuestro esquema. Todas las operaciones de base de datos realizadas en un documento con Mongoose deben hacer referencia a un modelo.\nEl Esquema El schema es la estructura que van a tener nuestros datos. Nos permite decidir exactamente qué datos queremos y qué opciones que los datos tengan como objeto.\nconst mongoose = require(\u0026#34;mongoose\u0026#34;); const FoodSchema = new mongoose.Schema({ nombre: { type: String, required: true, trim: true, lowercase: true, }, calorias: { type: Number, default: 0, validate(value) { if (value \u0026lt; 0) throw new Error(\u0026#34;Las calorias negativas no son reales.\u0026#34;); }, }, }); const Food = mongoose.model(\u0026#34;Food\u0026#34;, FoodSchema); module.exports = Food; Consiste en un nombre, de tipo String, será obligatorio, se limpian espacios en blanco y estará en minúsculas. También tendremos calorías, de tipo numérico, un valor por defecto de 0 y una validación para que no pueda ser menor a 0.\nCRUD con Mongoose Cuando quieres hacer un nuevo registro creas una nueva instancia de tu modelo e invocas al método save. En este caso estoy definiendo las propiedades manualmente, pero pueden venir de cualquier lugar.\nconst videojuego = new Videojuego({ nombre: \u0026#34;Cuphead\u0026#34;, precio: 180, calificacion: 10, }); await videojuego.save(); console.log(\u0026#34;Guardado\u0026#34;); Cuando quieres obtener todos los registros, invoca al método find:\nconst videojuegos = await Videojuego.find(); console.log(videojuegos); Si quieres obtener un registro por id, invoca a findById:\nconst id = \u0026#34;12354564asdf\u0026#34;; const videojuego = await Videojuego.findById(id); console.log(videojuego); En el caso de actualizar un registro por id puedes usar a findOneAndUpdate:\nconst id = \u0026#34;1235213asdf\u0026#34;; await Videojuego.findOneAndUpdate({ _id: id, }, { nombre: \u0026#34;Nuevo nombre\u0026#34;, precio: 500, calificacion: 9, }); console.log(\u0026#34;Actualizado\u0026#34;); Y finalmente para eliminar un registro a partir del ID puedes usar findOneAndDelete:\nconst id = \u0026#34;123213asdf\u0026#34;; await Videojuego.findOneAndDelete({ _id: id }); console.log(\u0026#34;Eliminado\u0026#34;); Conclusión MongoDB nos proporciona las ventajas de una base de datos NoSQL, como la flexibilidad de la estructura de datos, la escalabilidad y el rendimiento sin abandonar conceptos que han hecho a las bases de datos relacionales lo que son hoy en día, como consistencia de datos y la integración con otras herramientas de desarrollo. Sumado al poder administrarla en la nube con Mongo Atlas (solución provista por los creadores del producto).\nPor estas características, MongoDB es una herramienta que cae como anillo al dedo para el desarrollo de aplicaciones como redes sociales, aplicaciones móviles, CMS, entre otras, que debido a lo antes mencionado, requieren de una base de datos que ofrezca alto rendimiento y flexibilidad, a la vez que mantiene consistencia y seguridad en los datos.\nConsideramos que MongoDB es una herramienta fácil de aprender, útil y sumamente divertida. Principalmente al estar trabajando en proyectos personales o por hobby, no tenemos que pasar por todo el proceso de definición y esquema de tablas y relaciones. Sencillamente con que esté corriendo MongoDB ya le podemos enviar información desde nuestras aplicaciones.\nEs idóneo además de que como en nuestro caso lo usamos en conjunto con Node y React, tampoco es necesario aprender varios lenguajes para realizar una aplicación completa. Decidimos utilizar Node debido a su popularidad en la industria, también el hecho de que nos pareció copado trabajar con el Stack MERN - Mongo Express React y Node. NodeJS nunca fue hecho para resolver el problema de escalado de computación. Node fue creado para resolver el problema de escalado de E/S, lo que funciona de maravilla. Entonces cuándo usarlo? La respuesta es simple, si el problema no contiene operaciones intensivas de CPU ni el acceso a los recursos de bloqueo, node es la respuesta.\n"},{"id":9,"href":"/programa-analitico/unidad-02/","title":"UNIDAD 2","parent":"Programa Analítico","content":" Servicios de BackEnd y servidores de aplicaciones Arquitecturas de sistemas cliente servidor de 2 y 3 capas. Como se implementa una capa de negocios. Objetos basados en clases reutilizables. Modelos de ejecución actuales. Máquinas virtuales, containers y virtualización a nivel SO. Compiladores just-in-time. Distribución de aplicaciones a través de la red. Frameworks de persistencia, hibernate, JPA.\nObjetivos específicos Seleccionar y aplicar correctamente las tecnologías existentes en el mercado. Que sepa analizar el contexto del problema y resuelva el mismo con la mejor herramienta posible. "},{"id":10,"href":"/teoria-practicos/patrones/","title":"Patrones de Acceso a Datos","parent":"Teoría Trabajos Prácticos","content":" Patrón Repositorio El patrón repositorio consiste en separar la lógica que recupera los datos y los asigna a un modelo de entidad de la lógica de negocios que actúa sobre el modelo, esto permite que la lógica de negocios sea independiente del tipo de dato que comprende la capa de origen de datos, en pocas palabras un repositorio media entre el dominio y las capas de mapeo de datos, actuando como una colección de objetos de dominio en memoria\nVer presentación: Acceso Datos\nData Mappers Es una capa de software que separa los objetos en memoria de la base de datos. Su responsabilidad es transferir datos entre los dos y también aislarlos entre sí. Con Data Mapper, los objetos en memoria no necesitan saber ni siquiera que hay una base de datos presente; no necesitan código de interfaz SQL y, ciertamente, ningún conocimiento del esquema de la base de datos.\nDAO El patrón DAO propone separar por completo la lógica de negocio de la lógica para acceder a los datos, de esta forma, el DAO proporcionará los métodos necesarios para insertar, actualizar, borrar y consultar la información; por otra parte, la capa de negocio solo se preocupa por lógica de negocio y utiliza el DAO para interactuar con la fuente de datos.\nCapa de Acceso a Datos: Capa externa que va a contener todas las fuentes de datos desde donde vamos a extraer dichos datos para leerlos desde nuestra capa de dominio.\nQuery Object Un objeto de consulta es un intérprete, es decir, una estructura de objetos que puede formarse en una consulta SQL. El patrón de objeto de consulta en realidad utiliza el patrón de asignación de metadatos para generar consultas de base de datos reales.\nCapa de Dominio: Es una capa que contiene todas las clases que forman parte de nuestra lógica del negocio que vamos a implementar.\nCapa de Servicio: Es una capa que contendrá todos los métodos desde los cuales se realizarán las peticiones hacia la fuente de datos respectiva.\nVentajas y Desventajas Ventajas Desventajas Reutilización del código de acceso a datos Implementación compleja Lógica del dominio sencilla de probar Requiere un nivel adicional de direccionamiento indirecto Nos ayuda en el desacople de la lógica Alto grado de dependencia en la interfaz de fachada Permite implementar varias fuentes de persistencia de datos Permite inyección de dependencia Aplicación de capas API La interfaz de programación de aplicaciones, conocida también por la sigla API,application programming interface, es un conjunto de subrutinas, funciones y procedimientos (o métodos, en la programación orientada a objetos) que ofrece cierta biblioteca para ser utilizado por otro software como una capa de abstracción. Es una especificación formal sobre cómo un módulo de un software se comunica o interactúa con otro, simplifican en gran medida el trabajo de un creador de programas, ya que no tiene que «escribir» códigos desde cero.\nSon un medio simplificado para conectar su propia infraestructura a través del desarrollo de aplicaciones nativas de la nube, pero también le permiten compartir sus datos con clientes y otros usuarios externos. No son la parte visible, sino los circuitos internos que sólo los desarrolladores ven y conectan para hacer funcionar una herramienta. Por ejemplo, cuando el usuario compra entradas a través de la página web de una sala de cine e introduce la información de su tarjeta de crédito, la web usa una API para enviar dicha información de forma remota a otro programa que verifica si los datos bancarios son correctos. Una vez que se confirma el pago, la aplicación remota envía la información al sitio web del cine y le da un «OK», por lo que esta página emite los tickets.\nREST (Representational State Transfer) Es un estilo de arquitectura de software, es cualquier interfaz entre sistemas que use HTTP para obtener datos o generar operaciones sobre esos datos en todos los formatos posibles. A partir de donde podemos establecer lo siguiente:\nTodo es un recurso y viene representado por un formato. Cada recurso tiene un único identificador y es accesible mediante una URI. Para operar con un recurso usaremos los verbos de HTTP (GET, POST, PUT, DELETE, PATCH). Cada recurso puede tener múltiples representaciones (por ejemplo se podría representar mediante json, yaml, o xml). El protocolo de comunicación se considera sin estado (cada operación con el recurso se trata de forma totalmente aislada) RESTful APIs REST es el estándar más lógico, eficiente y habitual en la creación de APIs. Para que una API se considere RESTful debe cumplir una serie de criterios: Un Restful API es una aplicación que usa el protocolo cliente-servidor sin estado (no se almacena la información del cliente entre las solicitudes) compuesta de clientes,servidores y recursos, gestionando solicitudes a través de HTTP. Debe hacer uso de hipermedios, llevado al desarrollo de páginas web es lo que permite que el usuario puede navegar por el conjunto de objetos a través de enlaces HTML. En el caso de una API REST, el concepto de hipermedia explica la capacidad de una interfaz de desarrollo de aplicaciones de proporcionar al cliente y al usuario los enlaces adecuados para ejecutar acciones concretas sobre los datos. Una arquitectura basada en capas nos permite mantener una separación de conceptos, buscando la máxima cohesión y el menor acoplamiento de los componentes. En este caso, la arquitectura basada en capas que vamos a desarrollar, tiene los siguientes componentes: controladores, servicio y repositorio\nControladores Es una capa que sirve de enlace entre las vistas y los modelos, respondiendo a mecanismos que puedan ser necesitados al momento de implementar las necesidades de la aplicación. Esta capa contiene muy poca lógica y se utiliza para realizar llamadas a servicios. Se encarga de realizar comprobaciones básicas de los datos devueltos por los servicios para enviar una respuesta al cliente, Recibiendo solicitudes de vista y realizando solicitudes de vistas para mostrar resultados a los usuarios. Usamos los controladores para mapear las uris (identificadores unívocos de los recursos lógicos o físicos usados por las tecnologías web) de entrada del API REST. En el controlador:\nObtenemos los datos que nos entran al servidor mediante las llamadas HTTP al API REST. Los preparamos para llamar a los servicios que operan con ellos. Con el resultado devuelto, lo preparamos para ser enviado. Servicios Los servicios se encargan de la lógica de negocio de nuestra aplicación. En esta capa se dice que hacer con los datos (guardados en la capa de repositorio) por lo que tiene que estar conectada con la capa de repositorio. El término lógica de negocio hace referencia a la parte de un sistema que se encarga de codificar las reglas de negocio del mundo real que determinan cómo la información puede ser creada, almacenada y cambiada. Son rutinas que realizan entrada de datos, consultas, generación de informes. Esta capa está presente, específicamente, en todo el procesamiento que se realiza detrás del Backend, la aplicación visible para el usuario. Los servicios pueden llamar a otros servicios para interactuar con ellos, y por supuesto a los repositorios, que es dónde se encuentran los datos de la aplicación.\nRepositorios En los repositorios tenemos acceso directo a los datos de la aplicación, y desacoplan de cómo se almacena esta información para que los servicios no tengan que conocerla. Se utiliza entre la capa de modelo y servicio. Aquí es dónde se opera con los datos, se accede a ellos, se realizan los filtros necesarios y las modificaciones que necesitemos. Una vez realizada su tarea, devuelve los datos a los servicios.\n"},{"id":11,"href":"/programa-analitico/unidad-03/","title":"UNIDAD 3","parent":"Programa Analítico","content":" El cliente liviano Desarrollo con clientes livianos, el rol de los navegadores de internet en las tecnologías actuales. HTML. Arquitectura de un navegador de internet. Aplicaciones para Web: escenarios que soluciona. HTML dinámico: formas de generarlo. Arquitectura del servidor HTTP. Guiones (scripts). Scripting de lado del servidor. Scripting del lado del cliente. Lenguajes de scripting, generalidades. Formularios Web: qué son, cómo funcionan. Aplicaciones HTTP. Mantenimiento de sesiones. Estructuras de memoria, y estructuras relacionales para mantener sesiones. Cabecera HTTP. Acceso a bases de datos del lado del servidor. Seguridad de sistema web, frameworks de membresía. Consideraciones con barreras cortafuegos, enrutadores, proxies. Generalidades de capa de conexión segura (SSL). Firmas digitales, autoridad de internet. HTML5, escenarios que soluciona. Manejos de la visual con hojas de estilos en cascada y estilos XSLT. Javascript con Jquery.\nObjetivos específicos Dominar las bases de las aplicaciones basadas en internet. "},{"id":12,"href":"/teoria-practicos/solid/","title":"Principios SOLID","parent":"Teoría Trabajos Prácticos","content":" ¿Qué son los Principios SOLID? Son un conjunto de principios aplicables a la Programación Orientada a Objetos que, si los usas correctamente, te ayudarán a escribir software de calidad en cualquier lenguaje de programación orientada a objetos. Gracias a ellos, crearás código que será más fácil de leer, testear y mantener.\nLos principios en los que se basa SOLID son los siguientes:\n● Principio de Responsabilidad Única (Single Responsibility Principle)\n● Principio Open/Closed (Open/Closed Principle)\n● Principio de Sustitución de Liskov (Liskov Substitution Principle)\n● Principio de Segregación de Interfaces (Interface Segregation Principle)\n● Principio de Inversión de Dependencias (Dependency Inversion Principle)\nEstos principios son la base de mucha literatura que encontrarás en torno al desarrollo de software: muchas arquitecturas se basan en ellos para proveer flexibilidad, el testing necesita confiar en ellos para poder validar partes de código de forma independiente, y los procesos de refactorización serán mucho más sencillos si se cumplen estas reglas.\nFueron publicados por primera vez por Robert C. Martin, también conocido como Uncle Bob, en su libro Agile Software Development: Principles, Patterns, and Practices.\n¿Qué beneficios aporta usar los Principios SOLID? Las ventajas de utilizar los Principios SOLID son innumerables, ya que nos aportan todas esas características que siempre queremos ver en un software de calidad.\nEn cada uno de los principios nos iremos centrando en qué aportan específicamente, pero es interesante hacer un resumen general de lo que conseguiremos con ellos:\nSoftware más flexible: mejoran la cohesión disminuyendo el acoplamiento. Lo que buscamos de un buen código es que sus clases puedan trabajar de forma independiente y que el cambio de uno afecte lo menos posible al resto. Obviamente cuando dos clases se relacionan entre sí para trabajar juntas (y esto tiene que ocurrir sí o sí), va a existir un acoplamiento entre ellas. Pero existen distintos niveles de acoplamiento, y gracias a algunos de los Principios SOLID, podemos relajar esas dependencias y hacerlas mucho más flexibles a cambios.\nTe van a hacer entender mucho mejor las arquitecturas\nEsto es porque primero hace falta entender los principios sobre los que se sustentan, y los principios SOLID son muy importantes para ello.\nSimplifican la creación de tests\nTodo esto está muy relacionado con los puntos anteriores: si tienes tu código desacoplado y una buena arquitectura, los tests van a ser mucho más sencillos.\nLos Principios SOLID están muy interrelacionados\nEstos principios actúan como un todo. No es casualidad que se expliquen de forma conjunta. Y esto tiene dos consecuencias muy importantes de entender:\n● Unos principios no pueden existir sin los otros\nPor ejemplo, si se tiene una clase A que tiene un acoplamiento muy fuerte con una clase B, de tal forma que cada vez que cambia B inevitablemente tiene que cambiar A. Esto es muy posible que esté incumpliendo el Principio de Responsabilidad Única. La forma de cumplirlo sería haciendo que cuando B cambie, A no lo haga. Y para esto, la solución puede ser aplicar el Principio de Inversión de Dependencias. Esto es muy normal y pasa casi siempre.\nUn mismo problema se puede resolver desde dos perspectivas distintas en función de en qué Principio nos enfoquemos cuando lo resolvamos. Pero el resultado será el mismo.\n● Al cumplir un Principio puede que estés incumpliendo otro\nEsto es lo más difícil de aceptar: muchas veces es imposible cumplir todos los Principios a la vez. Porque al aplicar un Principio, se puede estar dando la espalda a otro. Al final lo importante es entender la potencia de cada Principio.\nPrincipio de Responsabilidad Única (Single Responsibility Principle) El Principio de responsabilidad única es el primero de los cinco que componen SOLID.\nEl principio de Responsabilidad Única nos viene a decir que un objeto debe realizar una única cosa. Es muy habitual, si no prestamos atención a esto, que acabemos teniendo clases que tienen varias responsabilidades lógicas a la vez.\n¿Cómo detectar si estamos violando el Principio de Responsabilidad Única? La respuesta a esta pregunta es bastante subjetiva. Podemos detectar situaciones en las que una clase podría dividirse en varias:\nEn una misma clase están involucradas dos capas de la arquitectura: esta puede ser difícil de ver sin experiencia previa. En toda arquitectura, por simple que sea, debería haber una capa de presentación, una de lógica de negocio y otra de persistencia. Si mezclamos responsabilidades de dos capas en una misma clase, será un buen indicio. El número de métodos públicos: Si una clase hace muchas cosas, lo más probable es que tenga muchos métodos públicos, y que tengan poco que ver entre ellos. Detecta cómo se puede agrupar para separarlos en distintas clases. Los métodos que usan cada uno de los campos de esa clase: si tenemos dos campos, y uno de ellos se usa en unos cuantos métodos y otro en otros cuantos, esto puede estar indicando que cada campo con sus correspondientes métodos podría formar una clase independiente. Normalmente esto estará más difuso y habrá métodos en común, porque seguramente esas dos nuevas clases tendrán que interactuar entre ellas. Por el número de imports: Si necesitamos importar demasiadas clases para hacer nuestro trabajo, es posible que estemos haciendo trabajo de más. También ayuda fijarse a qué paquetes pertenecen esos imports. Si vemos que se agrupan con facilidad, puede que nos esté avisando de que estamos haciendo cosas muy diferentes. Nos cuesta testear la clase: si no somos capaces de escribir tests unitarios sobre ella, o no conseguimos el grado de granularidad que nos gustaría, es momento de plantearse dividir la clase en dos. Cada vez que escribes una nueva funcionalidad, esa clase se ve afectada: si una clase se modifica a menudo, es porque está involucrada en demasiadas cosas. Por el número de líneas: a veces es tan sencillo como eso. Si una clase es demasiado grande, intenta dividirla en clases más manejables. En general no hay reglas de oro para estar 100% seguros, pero estos indicios ayudarán a detectar algunos casos donde tengas dudas.\nPrincipio Open/Closed (Open/Closed Principle) Este principio nos dice que una entidad de software debería estar abierta a extensión, pero cerrada a modificación. ¿Qué quiere decir esto? Que tenemos que ser capaces de extender el comportamiento de nuestras clases sin necesidad de modificar su código.\nEsto nos ayuda a seguir añadiendo funcionalidad con la seguridad de que no afectará al código existente. Nuevas funcionalidades implicarán añadir nuevas clases y métodos, pero en general no debería suponer modificar lo que ya ha sido escrito.\nLa forma de llegar a ello está muy relacionada con el punto anterior. Si las clases sólo tienen una responsabilidad, podremos añadir nuevas características que no les afectarán. Esto no quiere decir que cumpliendo el primer principio se cumpla automáticamente el segundo, ni viceversa.\nEl principio Open/Closed se suele resolver utilizando polimorfismo. En vez de obligar a la clase principal a saber cómo realizar una operación, delega esta a los objetos que utiliza, de tal forma que no necesita saber explícitamente cómo llevarla a cabo. Estos objetos tendrán una interfaz común que implementarán de forma específica según sus requerimientos.\n¿Cómo detectar que estamos violando el principio Open/Closed? Una de las formas más sencillas para detectarlo es darnos cuenta de qué clases modificamos más a menudo. Si cada vez que hay un nuevo requisito o una modificación de los existentes, las mismas clases se ven afectadas, podemos empezar a entender que estamos violando este principio.\n¿Cuándo debemos cumplir con este principio? Hay que decir que añadir esta complejidad no siempre compensa, y como el resto de principios, sólo será aplicable si realmente es necesario.\nSi tienes una parte de tu código que es propensa a cambios, se lo debe plantear de forma que un nuevo cambio impacte lo menos posible en el código existente.\nIntentar hacer un código 100% Open/Closed es prácticamente imposible, y puede hacer que sea ilegible e incluso más difícil de mantener.\nPrincipio de Sustitución de Liskov (Liskov SubstitutionPrinciple) El principio de sustitución de Liskov nos dice que toda clase que es hija de otra clase, debe poder utilizarse como si fuese el mismo padre. Nadie debería comportarse de manera distinta si interactúa con la clase padre o hija.\nEsto nos obliga a asegurarnos de que los objetos en un programa deben ser capaces de ser reemplazados con instancias de subtipos de esos objetos sin alterar el programa. La primera en hablar de él fue Bárbara Liskov (de ahí el nombre), una reconocida ingeniera de software americana.\n¿Cómo detectar que estamos violando el principio de sustitución de Liskov? Seguro que te has encontrado con esta situación muchas veces: creas una clase que se extiende de otra, pero de repente uno de los métodos te sobra, y no sabes qué hacer con él. Las opciones más rápidas podrían ser dejarlo vacío, o lanzar una excepción cuando se use, asegurándose de que nadie llama incorrectamente a un método que no se puede utilizar. Si un método sobrescrito no hace nada o lanza una excepción, es muy probable que estés violando el principio de sustitución de Liskov.\nOtra herramienta que te avisará fácilmente son los tests. Si los tests de la clase padre no funcionan para la hija, también estarás violando este principio.\nPrincipio de Segregación de Interfaces (Interface Segregation Principle) El principio de segregación de interfaces viene a decir que ninguna clase debería depender de métodos que no usa. Por tanto, cuando creemos interfaces que definan comportamientos, es importante estar seguros de que todas las clases que implementen esas interfaces vayan a necesitar y ser capaces de agregar comportamientos a todos los métodos. En caso contrario, es mejor tener varias interfaces más pequeñas.\nLas interfaces nos ayudan a desacoplar módulos entre sí. Esto es así porque si tenemos una interfaz que explica el comportamiento que el módulo espera para comunicarse con otros módulos, nosotros siempre podremos crear una clase que lo implemente de modo que cumpla las condiciones.\nEl módulo que describe la interfaz no tiene que saber nada sobre nuestro código y, sin embargo, nosotros podemos trabajar con él sin problemas.\nEl problema La problemática surge cuando esas interfaces intentan definir más cosas de las debidas, lo que se denominan fat interfaces.\nProbablemente ocurrirá que las clases hijas acabarán por no usar muchos de esos métodos, y habrá que darles una implementación. Muy habitual es lanzar una excepción, o simplemente no hacer nada. Pero si lanzamos una excepción, es más que probable que el módulo que define esa interfaz use el método en algún momento, y esto hará fallar nuestro programa. El resto de implementaciones “por defecto” que podamos dar, pueden generar efectos secundarios que no esperemos, y a los que sólo podemos responder conociendo el código fuente del módulo en cuestión, cosa que no nos interesa.\n¿Cómo detectar que estamos violando el Principio de segregación de interfaces? Si al implementar una interfaz ves que uno o varios de los métodos no tienen sentido y te hace falta dejarlos vacíos o lanzar excepciones, es muy probable que estés violando este principio.\nPrincipio de Inversión de Dependencias (Dependency Inversion Principle) Gracias al principio de inversión de dependencias, podemos hacer que el código que es el núcleo de nuestra aplicación no dependa de los detalles de implementación, como pueden ser el framework que utilices, la base de datos, cómo te conectes a tu servidor, etc.\nTodos estos aspectos se especificarán mediante interfaces, y el núcleo no tendrá que conocer cuál es la implementación real para funcionar.\nLa definición que se suele dar es:\nA. Las clases de alto nivel no deberían depender de las clases de bajo nivel. Ambas deberían depender de las abstracciones.\nB. Las abstracciones no deberían depender de los detalles. Los detalles deberían depender de las abstracciones.\nEl problema En la programación vista desde el modo tradicional, cuando un módulo depende de otro módulo, se crea una nueva instancia y la utiliza sin más complicaciones. Esta forma de hacer las cosas, que a primera vista parece la más sencilla y natural, nos va a traer bastantes problemas posteriormente, entre ellos:\nLas partes más genéricas de nuestro código (lo que llamaríamos el dominio o lógica de negocio) dependerá por todas partes de detalles de implementación. Esto no es bueno, porque no podremos reutilizarlo, ya que estará acoplado al framework de turno que usemos, a la forma que tengamos de persistir los datos, etc. Si cambiamos algo de eso, tendremos que rehacer también la parte más importante de nuestro programa. No quedan claras las dependencias: si las instancias se crean dentro del módulo que las usa, es mucho más difícil detectar de qué depende nuestro módulo y, por tanto, es más difícil predecir los efectos de un cambio en uno de esos módulos. También nos costará más tener claro si estamos violando algunos otros principios, como el de Responsabilidad Única. Es muy complicado hacer tests: Si tu clase depende de otras y no tienes forma de sustituir el comportamiento de esas otras clases, no puedes testarla de forma aislada. Si algo en los tests falla, no tendrías forma de saber de un primer vistazo qué clase es la culpable. ¿Cómo detectar que estamos violando el Principio de inversión de dependencias? Cualquier instanciación de clases complejas o módulos es una violación de este principio. Además, si escribes tests te darás cuenta muy rápido, en cuanto no puedas probar esa clase con facilidad porque dependa del código de otra clase.\nEntonces cómo vamos a hacer para darle al módulo todo lo que necesita para trabajar. Habrá que utilizar alguna de las alternativas que existen para suministrar esas dependencias.\nAunque hay varias, las que más se suelen utilizar son mediante constructor y mediante setters (funciones que lo único que hacen es asignar un valor).\n¿Quién se encarga de proveer las dependencias? Lo más habitual es utilizar un inyector de dependencias: un módulo que se encarga de instanciar los objetos que se necesiten y pasárselos a las nuevas instancias de otros objetos. Se puede hacer una inyección muy sencilla a mano, o usar alguna de las muchas librerías que existen si necesitamos algo más complejo.\nConclusión Las reglas SOLID son ideas muy potentes que generan un gran aporte para crear software de calidad, pero hay que aplicarlas donde corresponda y sin obsesionarnos con cumplirlas en cada punto del desarrollo, por eso es importante entender bien todos los conceptos para no agregar errores a futuro. Por lo tanto, concluimos en que casi siempre es más sencillo limitarse a usarlas cuando nos haya surgido la necesidad real.\n"},{"id":13,"href":"/programa-analitico/unidad-04/","title":"UNIDAD 4","parent":"Programa Analítico","content":" Aplicaciones distribuidas y servicios de internet Evolución de los sistemas distribuidos. Desarrollo de aplicaciones distribuidas con clientes pesados y decodificadores de XML. Servicios Web en la internet. Protocolo de acceso simple a objetos SOAP. Modelo REST, Open Data Protocol, ATOM, JSON. Estándares basados en el modelo REST. Generalidades de JSON y su comparación con XML. HTML 5 Websockets. WebAPI. Conexiones long-polling, forever frame, server-sent events y websockets, ventajas y desventajas. Ejemplos de uso.\nObjetivos específicos Diseñar un sistema distribuido basado en redes públicas "},{"id":14,"href":"/teoria-practicos/rest/","title":"REST","parent":"Teoría Trabajos Prácticos","content":" REpresentational State Transfer Transferencia de estados representacionales REST es una interfaz para conectar varios sistemas basados en el protocolo HTTP y nos sirve para obtener y generar datos y operaciones, devolviendo esos datos en formatos muy específicos, como XML y JSON.\nREST se apoya en HTTP\nLos verbos que utiliza son exactamente los mismos, con ellos se puede hacer GET, POST, PUT y DELETE.\nVer presentación: REST API\nPara que una API sea considerada como REST debe superar las siguientes características arquitectónicas ● Uso de una interfaz uniforme\n● Modelo Cliente-Servidor\n● Operaciones sin estado\n● Almacenamiento en caché\n● Sistema de capas\n● Código de baja demanda\nRest retorna código de status HTTP como respuesta. Los más conocidos son:\n● 200: Ok\n● 201: Creado\n● 401: Sin autorización\n● 403: Prohibido\n● 404: Recurso no encontrado\n● 500: Error de servidor\n¿Por qué debemos utilizar REST? REST no es solo una moda, y es por las siguientes razones que esta interfaz está teniendo tanto protagonismo en los últimos años:\nCrea una petición HTTP que contiene toda la información necesaria, es decir, un REQUEST a un servidor que almacena esa información y solo espera una RESPONSE. Se apoya sobre un protocolo que es el que se utiliza para las páginas web, que es HTTP. Se apoya en los métodos básicos de HTTP, como son:\n○ Post: Para crear recursos nuevos.\n○ Get: Para acceder a los distintos recursos.\n○ Put: Para modificar. ○ Patch: Para modificaciones parciales. ○ Delete: Para borrar un recurso o un dato, por ejemplo de nuestra base de datos. Todos los objetos se manipulan mediante URI Ventajas de REST Nos permite separar el cliente del servidor Esto quiere decir que nuestro servidor se puede desarrollar en Node y Express, y nuestra API REST con Vue por ejemplo, no tiene por qué estar todos dentro de uno mismo.\nPosee una gran Comunidad En la actualidad tiene una gran comunidad como proyecto en Github y en distintos lenguajes de programación.\nIndependencia de tecnologías / lenguajes Es totalmente independiente de la plataforma, así que podemos hacer uso de REST tanto en Windows, Linux, Mac o el sistema operativo que nosotros queramos.\nEscalabilidad, Fiabilidad, flexibilidad Nos da escalabilidad, porque tenemos la separación de conceptos de CLIENTE y SERVIDOR, por tanto, podemos dedicarnos exclusivamente a la parte del servidor.\nA la hora de ejecutar tu aplicación también tienes una flexibilidad mucho mayor. Por las características de REST (principalmente no guardar estado) es indiferente qué servidor atienda cada solicitud, pues es el propio cliente el que tiene que mandar el estado al servidor.\nLa escalabilidad que aporta es gracias a una serie de características que presenta la arquitectura REST:\n◎ Es un protocolo sin estado, debido a que no se guarda la información en el servidor. Es decir, toda la información será enviada por el cliente en cada mensaje HTTP, consiguiendo un ahorro en variables de sesión y almacenamiento interno del servidor.\n◎ Presenta un conjunto de operaciones bien definidas, siendo las más importantes GET, PUT, POST y DELETE, que se emplean en todos los recursos.\n◎ Utiliza URIs únicas siguiendo una sintaxis universal.\n◎ Emplea hipermedios para representar la información, que suelen ser HTML, XML o JSON.\nAdicionalmente Podemos crear un diseño de un microservicio orientado a un dominio (DDD) Podemos hacer nuestra API pública, permitiendo el acceso a quien quiere hacer uso de nuestra API dándonos mayor visibilidad. ¿Quién usa REST? Muchas empresas como Twitter, Facebook, Google, Netflix, LinkedIn y miles de startups y empresas usan REST. Todos estas empresas y servicios tienen su API REST por un lado con su lógica de negocio y por otro lado su parte frontend, con lo cual nos permite centrarnos también un poco más en lo que es nuestra lógica de negocio haciendo una API REST potente.\nDesventajas de REST Cambiar el modo de pensar para los equipos de trabajo. Mayor tiempo de desarrollo porque hay que montar todo el sistema de la API. Requiere más conocimientos. Montar una infraestructura propia. Pueden presentarse circunstancias de mayor rigidez en el desarrollo y surgir situaciones de des-sincronización. Seguridad en REST API Ver presentación:\nSeguridad REST API "},{"id":15,"href":"/programa-analitico/unidad-05/","title":"UNIDAD 5","parent":"Programa Analítico","content":" Frameworks de desarrollo de uso en la industria La tecnología .Net, Java, Golang, Rust. Similitudes y diferencias en el modelo de ejecución. Arquitectura de las máquinas virtuales específicas. Clientes pesados. Clientes livianos. Objetos de negocio. Capa de acceso a datos. Framework de persistencia. Capa de fachada web y cliente inteligente. Entornos integrados de desarrollo. Ciclos de vida de una aplicación. Servicios de los entornos de desarrollo integrados (IDE) modernos. Servidores de integración continua. Ciclo de vida de proyectos basado en la nube.\nObjetivos específicos: Familiarizarse con las grandes familias de plataformas tecnológicas en uso en la industria mundial. "},{"id":16,"href":"/teoria-practicos/mvc/","title":"MVC","parent":"Teoría Trabajos Prácticos","content":" ¿Qué es MVC (Modelo Vista Controlador)? Es un patrón de diseño de arquitectura de software.\nVer presentaciones:\nPatrón MVC ASP.NET MVC Modelo El modelo contiene principalmente las entidades que representan el dominio, la logica de negocio y los mecanismos de persistencia de nuestro sistema.\nVista En la vista encontraremos los componentes responsables de generar la interfaz con el exterior, por regla general, aunque no exclusivamente, el UI de nuestra aplicación.\nControlador En el controlador se encuentran los componentes capaces de procesar las interacciones del usuario, consultar o actualizar el modelo y seleccionar las vistas apropiadas en cada momento.\nVentajas Separación del Modelo de la Vista. Crea independencia de funcionamiento. Facilita agregar nuevos tipos de datos. Facilita el mantenimiento en caso de errores. Ofrece maneras más sencillas para probar el correcto funcionamiento del sistema. Pruebas de funcionamiento más sencillas. Permite el escalamiento de la aplicación en caso de ser requerido. Desventajas Agrega complejidad del sistema. Incrementan los archivos a mantener y desarrollar. Aumenta la dificultad de aprendizaje SOAP Web Services Ver presentación:\nSOAP Web Services "},{"id":17,"href":"/programa-analitico/unidad-06/","title":"UNIDAD 6","parent":"Programa Analítico","content":" Las tecnologías emergentes: la Nube Comparativa entre sistemas en la nube y sistemas sobre demanda. El software como servicio. La infraestructura como servicio. El ecosistema de desarrollo, venta de aplicaciones, entorno de ejecución, dependencia de servicios específicos basados en la nube: localización y seguimiento, licenciamiento, autenticación y autorización distribuidas. Servicios en la nube para clientes convencionales y para dispositivos móviles. Comparativas entre Amazon Cloud Services, Windows Azure, Google Apps, y su integración con las IDEs correspondientes. Kuberntes y las arquitecturas de microservicios y los service mesh.\nObjetivos específicos Diseñar un sistema basado en servicios en la nube. "},{"id":18,"href":"/teoria-practicos/node-frameworks/","title":"Frameworks en Node.js","parent":"Teoría Trabajos Prácticos","content":" Express.js Express.js es el framework de Node.js más utilizado. Es un framework minimalista que permite crear aplicaciones Web y APIs. Posee una arquitectura rápida, robusta y asíncrona.\nSu API permite a los usuarios configurar rutas para enviar/recibir peticiones entre el front-end y la base de datos (actuando como un marco de trabajo del servidor HTTP). Una buena ventaja de express es que soporta muchos otros paquetes y otros motores de plantillas como Pug, Mustache, EJS y muchos más.\nExpress se alinea con operaciones de E/S de alta velocidad y con la naturaleza “single-threaded” (un sólo hilo) de Node, haciéndolo casi un requerimiento por default para apps desarrolladas con Node.js.\nCaracterísticas: ● Paquetes veloces del lado del servidor. Express incorpora muchas características de node como funciones que pueden acelerar el proceso con pocas líneas de código.\n● Alta performance, múltiples operaciones pueden ser ejecutadas independientemente de otras utilizando programación asíncrona.\n● Alta cobertura de testing.\n● Gran abanico de herramientas de HTTP, lo que resulta en programas más reusables y fáciles de entender.\n● Better content negotiation- this helps in better communication between the client and server by providing HTTP headers to URLs, which fetch the exact information for the users/client-side.\nPatrón MVC Cuándo usar Express.js.\nSe pueden desarrollar aplicaciones más rápido ya que cuenta con bases disponibles para la generación de APIs. Se puede usar en casi cualquier nivel empresarial porque tiene un enrutamiento robusto, plantillas, infraestructura de seguridad y soporte de errores.\nResulta adecuado para cualquier tipo de aplicaciones web o móvil de cualquier tamaño. Para los equipos de desarrolladores principiantes esta es el mejor framework porque cuentan con una comunidad disponible para apoyarlos.\nHapi.js Hapi.js es un framework open-source para aplicaciones web. Es utilizado para crear servidores proxy, REST APIs y otras aplicaciones de escritorio ya que el framework es conocido por su confianza y alto contenido en todo lo que se refiera a seguridad. Tiene una basta cantidad de plugins incorporados para evitar utilizar middleware no oficial.\nCaracterísticas: ● Aplicaciones escalables\n● Mínimos gastos generales\n● Medidas de seguridad por default\n● Rico ecosistema\n● Rapido y facil arreglo de errores\n● Compatibilidad con MySQL, MongoDB y otras bases de datos\n● Compatible con REST APIs y aplicaciones HTTPS proxy ● Cacheo, autenticación y validación de entrada por default\nCuándo utilizar Hapi.js Hapi.js se puede utilizar cuando se quiere desarrollar con mayores medidas de seguridad, se desea un sistema escalable, en tiempo real y/o con aplicaciones orientadas al social-media. Los desarrolladores usualmente lo utilizan para crear servidores proxies y APIs.\nSocket.io Socket.io es una librería de JavaScript utilizada para desarrollar aplicaciones en tiempo real y establecer una comunicación bidireccional entre clientes y servidores. También es utilizado para construir aplicaciones con requerimientos de desarrollo de websocket. Por ejemplo, aplicaciones de chat como WhatsApp, que necesitan estar funcionando continuamente y actualizando su contenido en tiempo real, recargando los procesos de fondo para capturar las actualizaciones o mensajes. También ofrece análisis de la aplicación en tiempo real con unas pocas líneas de código. Más de mil compañías, incluidas Bepro, Barogo y Patreon utilizan esta librería.\nCaracterísticas: ● Soporte binario (con una librería del lado del cliente y otra del lado del servidor)\n● Soporte de multiplexación\n● Confiabilidad\n● Soporte de auto-reconexión\n● Detección de errores y autocorrección\n● Similar APIs for a client and server-side development\nCuándo utilizar Socket.io Socket.io permite desarrollar aplicaciones en tiempo real en las que los servidores necesitan enviar datos sin ser éstos requeridos por el lado del cliente (aplicaciones de chat, de videoconferencias, juegos multijugador)\nSails.js Sails.js se asemeja a la arquitectura MVC con patrones vistos en otros frameworks como Ruby on Rails y provee soporte para un desarrollo moderno y orientado a los datos. Es compatible con todas las bases de datos y flexible integrando frameworks de Javascript. Las APIs están basadas en datos, con una arquitectura escalable orientada a servicios.\nEs muy práctico para crear aplicaciones customizadas de alto nivel. Sus políticas para la escritura de código ayudan a reducir la cantidad necesitada de código, permitiendo la integración con módulos NPM al ser más flexible y abierto.\nSi bien es una plataforma con un frontend-agnostic-backend, este framework utiliza Express para lo que son las request HTTP y Socket.io para los WebSockets\nTambién permite compartir la misma API utilizada por otro servicio web u otro equipo de desarrollo, lo cual ayuda disminuyendo los tiempos y el esfuerzo. Sails agrupa un ORM, que hace posible la compatibilidad con casi todas las bases de datos, llegando incluso a proporcionar un gran número de proyectos comunitarios. Algunos de sus adaptadores oficialmente soportados incluyen MYSQL, MongoDB, PostgreSQL, Redis, e incluso Local Disk.\nCaracterísticas: ● REST APIs auto-generadas\n● Políticas de seguridad reutilizables\n● Backend agnóstico (el framework es independiente de cualquier frontend)\n● ORM (Object Relational Mapping) compatible con integración de base de datos de Express para las request HTTP y de Socket.io para WebSockets. Cuando utilizar Sails.js\nDebido a su precisión, simplificación de datos y funciones middleware reutilizables, se puede construir aplicaciones de chat customizadas con este framework.\nPosee una excelente compatibilidad con Socket.io, haciéndolo muy útil para aplicaciones como juegos y de redes sociales. Sails.js también es muy común para aplicaciones Node.js customizadas a escala empresarial.\nSe pueden producir apps listas para producción en cuestión de semanas, además se asemeja al patrón de arquitectura MVC utilizado en Ruby on Rails. Sin embargo, no es muy utilizado para la creación de pequeñas apps. Esto se debe a que Sails tiene algunas limitaciones en su flexibilidad cuando se trata de personalizaciones de alto nivel como con Express.\nExpress.js Hapi.js Socket.io Sails.js Performance Rápido Media - alta Media. Se vuelve lenta cuando se escala Media. Se enfoca en mejorar la eficiencia del desarrollador por sobre la performance Soporte de la comunidad Masivo. Posee una comunidad donde se manejan un montón de preguntas y respuestas Amplio soporte, posee una gran comunidad en github Soporte amplio Gran soporte, ya que es un framework bien establecido desde hace bastante tiempo Facilidad de uso Depende la dificultad del proyecto, generalmente sencillo de aprender Fácil. Posee una amplia cantidad de plugins que facilitan su uso Fácil porque requiere que el programador sepa solo del framework Fácil porque cuenta con blueprints que hacen más fácil conectar las APIs con un código minimal Mejor para Pequeños y grandes proyectos. También es una buena forma de aprender cómo trabajar con Node Ideal para crear aplicaciones seguras, en tiempo real y escalables Generalmente usada en aplicaciones en tiempo real o apps que requieran un chat en vivo o sala de conferencias Proyectos medianos que necesitan implementarse rápido "},{"id":19,"href":"/categories/","title":"Categories","parent":"Fundamentación","content":""},{"id":20,"href":"/","title":"Fundamentación","parent":"","content":"La asignatura Desarrollo de Aplicaciones Cliente Servidor ha dado, en su dictado de más de una década, un contacto intenso con las herramientas de uso normal en la industria para el desarrollo y la ingeniería de software. En la actualidad estos conceptos generales siguen siendo válidos, pero han cambiado significativamente los detalles subyacentes en el diseño, programación, prueba, despliegue y mantenimiento de una aplicación cliente-servidor. El tráfico de internet generado por dispositivos táctiles y móviles es mayor que el de equipos de escritorio, y la introducción las nueves de datos fuerzan al ingeniero a dominar una nueva forma de crear aplicaciones altamente conectadas. Las tecnologías cliente-servidor han mutado, mayor mente desde un modelo monolítico a un modelo distribuido de micro-servicios, basado en infraestructuras basadas en contenedores, posibilitando el escalamiento horizontal. Un importante porcentaje de código de cualquier aplicación está relacionado con la administración de conectividad de datos sobre redes públicas, y por lo tanto se hace mandatorio enfocarse en los estándares emergentes y abiertos basados en internet, tanto en el cliente como en la infraestructura del servidor.\nLa adopción de los lenguajes de programación también han cambiado significativamente, pasando de lenguajes como javascript y golang, haciendo que los frameworks de ejecución cambien significativamente. Esto incluye servicios de soporte al ciclo de vida de una aplicación, desde el diseño hasta el mantenimiento de la misma, tanto en los modelos on-premise, como los basados en la nube. Igualmente, los sistemas convergentes son una realidad, al borrarse los límites entre los sistemas móviles y de escritorio, las técnicas de desarrollo también han mutado. Es evidente que semejante razón de cambio exige una materia de orientación eminentemente práctica y con contenido puesto al día, contemplando los conceptos tradicionales de la ingeniería de software cliente-servidor, pero haciendo énfasis práctico en los estándares emergentes de estos nuevos modelos, sobre todo en las nuevas tecnologías convergentes.\nObjetivos Generales de la asignatura Que el alumno profundice los conocimientos en el análisis, diseño y desarrollo de aplicaciones en la metáfora cliente-servidor. Que el alumno aplique las herramientas que el mercado ofrece para crear soluciones útiles a problemas reales, produciendo sistemas de alto rendimiento. Que el alumno tenga acceso a tecnologías de última generación. Que el alumno pueda desarrollar aplicaciones utilizando tecnologías emergentes, como ser la computación en la nube. "},{"id":21,"href":"/programa-analitico/","title":"Programa Analítico","parent":"Fundamentación","content":" UNIDAD 1: Introducción a las aplicaciones cliente-servidor Repaso de las arquitecturas más comunes en sistemas distribuidos. Modelo de capas. Dos y tres capas. Modelo de tres capas, la tendencia actual. Modelo distribuido y de microservices, introducción. Interfaces de acceso a los datos: ODBC, OLE DB y los objetos ADO. JDBC. Publicadores y consumidores de datos. Patrones de diseño en arquitecturas distribuidas, Event-Sourcing.\nObjetivos específicos Discriminar las diferencias conceptuales entre las distintas tecnologías existentes. "},{"id":22,"href":"/tags/","title":"Tags","parent":"Fundamentación","content":""},{"id":23,"href":"/teoria-practicos/","title":"Teoría Trabajos Prácticos","parent":"Fundamentación","content":" Sistemas de Control de Versionado Acceso a Datos ORM / ODM Patrones Acceso a Datos "},{"id":24,"href":"/trabajos-practicos/","title":"Trabajos Prácticos","parent":"Fundamentación","content":""}]